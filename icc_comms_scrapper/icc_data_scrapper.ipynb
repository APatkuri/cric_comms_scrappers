{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICC_SCHEDULE_URL = \"https://assets-icc.sportz.io/cricket/v1/schedule?client_id=tPZJbRgIub3Vua93%2FDWtyQ%3D%3D&feed_format=json&from_date=20000101&competition_type_ids=1&lang=en&league_ids=1%2C9&pagination=false&timezone=0530&to_date=20260101&timezone=0530\"\n",
    "\n",
    "response = requests.get(ICC_SCHEDULE_URL, timeout=100)\n",
    "data = response.json()\n",
    "\n",
    "\n",
    "os.makedirs(\"icc\", exist_ok=True)\n",
    "\n",
    "with open(\"icc/tests_2000_2025.json\", 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICC_COMMS_URL = \"https://assets-icc.sportz.io/cricket/static/json/iccteamlist/womens_international_teamlist.json\"\n",
    "\n",
    "# response = requests.get(ICC_COMMS_URL, timeout=100)\n",
    "# data = response.json()\n",
    "\n",
    "# with open(\"icc/icc_womens_international_teamlist.json\", \"w\") as f:\n",
    "#     json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICC_COMMS_URL = \"https://assets-icc.sportz.io/cricket/v1/game/commentary?client_id=tPZJbRgIub3Vua93/DWtyQ==&game_id=187175&pagination=false&inning=1&type=all&lang=en&feed_format=json\"\n",
    "# ICC_PLAYER_URL = \"https://assets-icc.sportz.io/cricket/v1/player?client_id=tPZJbRgIub3Vua93/DWtyQ==&feed_format=json&player_id=74837&lang=en\"\n",
    "# ICC_SCORECARD_URL = \"https://assets-icc.sportz.io/cricket/v1/game/scorecard?client_id=tPZJbRgIub3Vua93/DWtyQ==&game_id=1&lang=en&feed_format=json\"\n",
    "\n",
    "# response = requests.get(ICC_COMMS_URL, timeout=100)\n",
    "# data = response.json()\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# def fetch_free_proxies():\n",
    "#     \"\"\"Fetch free proxies from a reliable source\"\"\"\n",
    "#     try:\n",
    "#         # Free proxy list\n",
    "#         response = requests.get('https://free-proxy-list.net/')\n",
    "#         proxies = []\n",
    "        \n",
    "#         # Parse the HTML (you'll need to install beautifulsoup4)\n",
    "#         from bs4 import BeautifulSoup\n",
    "#         soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "#         for row in soup.find('table', {'class': 'table table-striped table-bordered'}).find_all('tr')[1:]:\n",
    "#             cols = row.find_all('td')\n",
    "#             if len(cols) > 1:\n",
    "#                 ip = cols[0].text.strip()\n",
    "#                 port = cols[1].text.strip()\n",
    "#                 proxies.append(f'http://{ip}:{port}')\n",
    "        \n",
    "#         return proxies[:10]  # Return first 10 proxies\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching proxies: {e}\")\n",
    "#         return []\n",
    "\n",
    "# def test_proxy(proxy, url='http://httpbin.org/ip'):\n",
    "#     \"\"\"Test if a single proxy works\"\"\"\n",
    "#     try:\n",
    "#         response = requests.get(\n",
    "#             url, \n",
    "#             proxies={'http': proxy, 'https': proxy}, \n",
    "#             timeout=5\n",
    "#         )\n",
    "#         return response.status_code == 200\n",
    "#     except:\n",
    "#         return False\n",
    "\n",
    "# def get_working_proxies(proxies, max_tries=5):\n",
    "#     \"\"\"Filter and return working proxies\"\"\"\n",
    "#     working_proxies = []\n",
    "#     for proxy in proxies:\n",
    "#         if test_proxy(proxy):\n",
    "#             working_proxies.append(proxy)\n",
    "#         if len(working_proxies) == max_tries:\n",
    "#             break\n",
    "#     return working_proxies\n",
    "\n",
    "# # Main script\n",
    "# def make_request_with_proxy(url):\n",
    "#     # Fetch proxies\n",
    "#     proxies = fetch_free_proxies()\n",
    "    \n",
    "#     # Get working proxies\n",
    "#     working_proxies = get_working_proxies(proxies)\n",
    "    \n",
    "#     if not working_proxies:\n",
    "#         print(\"No working proxies found!\")\n",
    "#         return None\n",
    "    \n",
    "#     # Try each working proxy\n",
    "#     for proxy in working_proxies:\n",
    "#         try:\n",
    "#             response = requests.get(\n",
    "#                 url, \n",
    "#                 proxies={'http': proxy, 'https': proxy}, \n",
    "#                 timeout=10\n",
    "#             )\n",
    "#             response.raise_for_status()\n",
    "#             return response\n",
    "#         except Exception as e:\n",
    "#             print(f\"Proxy {proxy} failed: {e}\")\n",
    "    \n",
    "#     return None\n",
    "\n",
    "# # Example usage\n",
    "# url = \"https://assets-icc.sportz.io/cricket/v1/schedule?client_id=tPZJbRgIub3Vua93%2FDWtyQ%3D%3D&feed_format=json&from_date=18000101&competition_type_ids=1&lang=en&league_ids=1%2C9&pagination=false&timezone=0530&to_date=19000101&timezone=0530\"\n",
    "# response = make_request_with_proxy(url)\n",
    "# data = response.json()\n",
    "\n",
    "# if response:\n",
    "#     print(\"Request successful!\")\n",
    "#     with open(\"icc/tests_1800_1900.json\", 'w') as f:\n",
    "#         json.dump(data, f, indent=4)\n",
    "# else:\n",
    "#     print(\"Could not make request with any proxy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_18_19 = pd.read_json('./icc/tests_1800_1900.json')\n",
    "df_19_20 = pd.read_json('./icc/tests_1900_2000.json')\n",
    "df_20_21 = pd.read_json('./icc/tests_2000_2025.json')\n",
    "\n",
    "match_df_18_19 = pd.DataFrame(df_18_19['data']['matches'])\n",
    "match_df_19_20 = pd.DataFrame(df_19_20['data']['matches'])\n",
    "match_df_20_21 = pd.DataFrame(df_20_21['data']['matches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'day',\n",
       " 'is_provisional_date',\n",
       " 'is_provisional_series_date',\n",
       " 'is_provisional_time',\n",
       " 'session'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_only_in_df1 = set(match_df_20_21.columns) - set(match_df_19_20.columns)\n",
    "columns_only_in_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tests_df = pd.concat([match_df_18_19, match_df_19_20, match_df_20_21], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_scores(scores):\n",
    "    single_row = {}\n",
    "    for inning in scores:\n",
    "        inning_no = inning['inning_no']\n",
    "        for key, value in inning.items():\n",
    "            if key != 'inning_no':  # Exclude 'inning_no' from the column names\n",
    "                column_name = f\"inning_{inning_no}_{key}\"\n",
    "                single_row[column_name] = value\n",
    "    return single_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_data = all_tests_df['scores'].apply(reshape_scores)\n",
    "reshaped_df = pd.DataFrame(reshaped_data.tolist())\n",
    "all_tests_df = pd.concat([all_tests_df.drop(columns='scores'), reshaped_df], axis=1)\n",
    "\n",
    "# all_tests_df = pd.concat([all_tests_df.drop(\"award\", axis=1), all_tests_df[\"award\"].apply(pd.Series).add_prefix('award')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_only_in_df1 = set(all_tests_df.columns) - set(match_df_20_21.columns)\n",
    "# columns_only_in_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_other_info(info):\n",
    "    # Flatten the dictionary into key-value pairs\n",
    "    return info\n",
    "\n",
    "reshaped_other_info = all_tests_df['other_info'].apply(reshape_other_info)\n",
    "reshaped_other_df = pd.DataFrame(reshaped_other_info.tolist())\n",
    "all_tests_df = pd.concat([all_tests_df.drop(columns='other_info'), reshaped_other_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_deleted', 'start_date', 'day_night', 'gmt_offset', 'group',\n",
       "       'league', 'league_id', 'live', 'live_coverage', 'comp_type_id',\n",
       "       ...\n",
       "       'inning_1_is_declare', 'inning_2_is_declare', 'inning_4_target',\n",
       "       'inning_2_is_followon', 'match_center', 'watch_live', 'high_light',\n",
       "       'blacklisted_countries', 'whitelisted_countries', 'ticket_link'],\n",
       "      dtype='object', length=136)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tests_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tests_df.to_csv(\"icc/icc_tests_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_match_id_df = all_tests_df['match_id']\n",
    "icc_match_id_df.to_csv(\"icc/icc_tests_match_id.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: match_id, dtype: object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_icc_match_id_df = all_tests_df['match_id'][all_tests_df['match_status'] == 'Stumps']\n",
    "latest_icc_match_id_df.to_csv(\"icc/icc_tests_comms_match_id.txt\", index=False)\n",
    "latest_icc_match_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_free_proxies():\n",
    "    \"\"\"Fetch free proxies from a reliable source\"\"\"\n",
    "    try:\n",
    "        # Free proxy list\n",
    "        response = requests.get('https://free-proxy-list.net/')\n",
    "        proxies = []\n",
    "        \n",
    "        # Parse the HTML (you'll need to install beautifulsoup4)\n",
    "        from bs4 import BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        for row in soup.find('table', {'class': 'table table-striped table-bordered'}).find_all('tr')[1:]:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                ip = cols[0].text.strip()\n",
    "                port = cols[1].text.strip()\n",
    "                proxies.append(f'http://{ip}:{port}')\n",
    "        \n",
    "        return proxies[:10]  # Return first 10 proxies\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching proxies: {e}\")\n",
    "        return []\n",
    "\n",
    "def test_proxy(proxy, url='http://httpbin.org/ip'):\n",
    "    \"\"\"Test if a single proxy works\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            url, \n",
    "            proxies={'http': proxy, 'https': proxy}, \n",
    "            timeout=5\n",
    "        )\n",
    "        return response.status_code == 200\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_working_proxies(proxies, max_tries=5):\n",
    "    \"\"\"Filter and return working proxies\"\"\"\n",
    "    working_proxies = []\n",
    "    for proxy in proxies:\n",
    "        if test_proxy(proxy):\n",
    "            working_proxies.append(proxy)\n",
    "        if len(working_proxies) == max_tries:\n",
    "            break\n",
    "    return working_proxies\n",
    "\n",
    "# Main script\n",
    "def make_request_with_proxy(url):\n",
    "    # Fetch proxies\n",
    "    proxies = fetch_free_proxies()\n",
    "    \n",
    "    # Get working proxies\n",
    "    working_proxies = get_working_proxies(proxies)\n",
    "    \n",
    "    if not working_proxies:\n",
    "        print(\"No working proxies found!\")\n",
    "        return None\n",
    "    \n",
    "    # Try each working proxy\n",
    "    for proxy in working_proxies:\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                url, \n",
    "                proxies={'http': proxy, 'https': proxy}, \n",
    "                timeout=10\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"Proxy {proxy} failed: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "# url = \"https://assets-icc.sportz.io/cricket/v1/schedule?client_id=tPZJbRgIub3Vua93%2FDWtyQ%3D%3D&feed_format=json&from_date=18000101&competition_type_ids=1&lang=en&league_ids=1%2C9&pagination=false&timezone=0530&to_date=19000101&timezone=0530\"\n",
    "# response = make_request_with_proxy(url)\n",
    "# data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_comms_info(match_id):\n",
    "\n",
    "    match_comms_data = []\n",
    "\n",
    "    for inn_no in range(1, 5):\n",
    "\n",
    "        ICC_COMMS_URL = f\"https://assets-icc.sportz.io/cricket/v1/game/commentary?client_id=tPZJbRgIub3Vua93/DWtyQ==&game_id={match_id}&pagination=false&inning={inn_no}&type=all&lang=en&feed_format=json\"\n",
    "        response = requests.get(ICC_COMMS_URL, timeout=100)\n",
    "        # response = make_request_with_proxy(ICC_COMMS_URL)\n",
    "        data = response.json()\n",
    "\n",
    "        if response:\n",
    "            print(\"Request successful!\")\n",
    "        else:\n",
    "            print(\"Could not make request with any proxy\")\n",
    "        \n",
    "        if(data['data'] != None):\n",
    "            print(f\"{match_id} INN {inn_no} MATCH COMMS THERE!!!\", match_id)\n",
    "            match_comms_data.append(data)\n",
    "\n",
    "    with open(f\"icc/test_matches/{match_id}.json\", 'w') as f:\n",
    "        json.dump(match_comms_data, f, indent=4)\n",
    "    # if(match_comms_data == []):\n",
    "    #     print(f\"{match_df} NO COMMS!!\", match_id)\n",
    "    # else:\n",
    "    #     print(f\"{match_id} DONE!!!\", match_id)\n",
    "        \n",
    "    # return match_comms_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "match_ids = []\n",
    "\n",
    "with open('icc/icc_tests_comms_match_id.txt', 'r') as file:\n",
    "    for l_no, i in enumerate(file):\n",
    "        if(l_no != 0):\n",
    "            match_ids.append(i.strip())\n",
    "    \n",
    "\n",
    "print(len(match_ids))\n",
    "for match_no in match_ids:\n",
    "    icc_comms_info(match_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reshape_comms_info(info):\n",
    "#     # Flatten the dictionary into key-value pairs\n",
    "#     return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reshape_comms_info(info):\n",
    "#     # Check if the info is a dictionary\n",
    "#     if isinstance(info, dict):\n",
    "#         # Flatten the dictionary into key-value pairs\n",
    "#         return info\n",
    "#     elif isinstance(info, list):\n",
    "#         # If the info is a list, create a dictionary with indexes\n",
    "#         return {f\"item_{i}\": item for i, item in enumerate(info)}\n",
    "#     else:\n",
    "#         # If it's neither a dictionary nor a list, return it as a single value\n",
    "#         return {0: info}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def icc_comms_cleaner(match_id):\n",
    "\n",
    "    df = pd.read_json(f\"./icc/test_matches/{match_id}.json\")\n",
    "    final_test_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        test_df = pd.DataFrame(df['data'][i]['Commentary'])\n",
    "        test_df = test_df.iloc[::-1].reset_index(drop=True)\n",
    "        test_df = test_df[test_df['Isball'] == True]\n",
    "\n",
    "        inn_no = i + 1\n",
    "        test_df.insert(0, 'Innings', inn_no)\n",
    "        test_df.insert(0, 'MatchID', match_id)\n",
    "\n",
    "        # if 'Batsman_Details' in test_df.columns:\n",
    "\n",
    "        #     reshaped_bat_det_info = test_df['Batsman_Details'].apply(reshape_comms_info)\n",
    "        #     reshaped_non_stkr_det_info = test_df['Non_Striker_Details'].apply(reshape_comms_info)\n",
    "        #     reshaped_bow_det_info = test_df['Bowler_Details'].apply(reshape_comms_info)\n",
    "\n",
    "        #     # Convert the reshaped data into a DataFrame\n",
    "        #     reshaped_bat_det_info = pd.DataFrame(reshaped_bat_det_info.tolist())\n",
    "        #     reshaped_non_stkr_det_info = pd.DataFrame(reshaped_non_stkr_det_info.tolist())\n",
    "        #     reshaped_bow_det_info = pd.DataFrame(reshaped_bow_det_info.tolist())\n",
    "\n",
    "        #     reshaped_bat_det_info.columns = [f\"curr_striker_{col}\" for col in reshaped_bat_det_info.columns]\n",
    "        #     reshaped_non_stkr_det_info.columns = [f\"curr_non_striker_{col}\" for col in reshaped_non_stkr_det_info.columns]\n",
    "        #     reshaped_bow_det_info.columns = [f\"curr_bowler_{col}\" for col in reshaped_bow_det_info.columns]\n",
    "\n",
    "        #     # Get the original index of the 'other_info' column\n",
    "\n",
    "        #     # non_stkr_index = test_df.columns.get_loc('Non_Striker_Details')\n",
    "        #     # bowler_index = test_df.columns.get_loc('Bowler_Details')\n",
    "        #     # bat_index = test_df.columns.get_loc('Batsman_Details')\n",
    "\n",
    "        #     # Drop the 'other_info' column\n",
    "\n",
    "        #     test_df = pd.concat([test_df, reshaped_non_stkr_det_info, reshaped_bow_det_info, reshaped_bat_det_info], axis=1)\n",
    "            \n",
    "        #     test_df = test_df.drop(columns=['Non_Striker_Details', 'Bowler_Details', 'Batsman_Details'])\n",
    "\n",
    "        #     # Insert reshaped data with new column names where 'other_info' was\n",
    "        #     for column_name in reshaped_non_stkr_det_info.columns:\n",
    "        #         test_df.insert(non_stkr_index, column_name, reshaped_non_stkr_det_info[column_name])\n",
    "        #         non_stkr_index += 1\n",
    "\n",
    "        #     for column_name in reshaped_bow_det_info.columns:\n",
    "        #         test_df.insert(bowler_index, column_name, reshaped_bow_det_info[column_name])\n",
    "        #         bowler_index += 1\n",
    "\n",
    "        #     for column_name in reshaped_bat_det_info.columns:\n",
    "        #         test_df.insert(bat_index, column_name, reshaped_bat_det_info[column_name])\n",
    "        #         bat_index += 1\n",
    "            \n",
    "            # test_df.drop(columns=['UID', 'OID', 'Bowler_Short_Name', 'Batsman_Short_Name', 'Non_Striker_Short_Name', 'This_Over', 'Ball_Speed_This_Over', 'Default_Commentary', 'Commentary'], inplace=True)\n",
    "            \n",
    "        # if 'Summary' in test_df.columns:\n",
    "            \n",
    "        #     if 'curr_striker_Batsman' in test_df.columns:\n",
    "        #         break\n",
    "        #     else:\n",
    "        #         reshaped_sum_info = test_df['Summary'].apply(reshape_comms_info)\n",
    "        #         reshaped_sum_info = pd.DataFrame(reshaped_sum_info.tolist())\n",
    "        #         reshaped_sum_info.columns = [f\"summary_{col}\" for col in reshaped_sum_info.columns]\n",
    "        #         test_df = test_df.drop(columns=['Summary'])\n",
    "        #         test_df = pd.concat([test_df, reshaped_sum_info], axis=1)\n",
    "\n",
    "\n",
    "        final_test_df = pd.concat([final_test_df, test_df], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "    final_test_df.to_csv(f\"./icc/test_matches/{match_id}.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_no in match_ids:\n",
    "    icc_comms_cleaner(match_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file ./icc/test_matches/253604.csv due to missing or empty 'Timestamp' column\n",
      "Skipping file ./icc/test_matches/243095.csv due to missing or empty 'Timestamp' column\n",
      "Skipping file ./icc/test_matches/244852.csv due to missing or empty 'Timestamp' column\n",
      "Skipping file ./icc/test_matches/249225.csv due to missing or empty 'Timestamp' column\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "csv_dir = \"./icc/test_matches/\"\n",
    "csv_files = glob.glob(csv_dir + \"*.csv\")\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    # dfs.append(df)\n",
    "\n",
    "    if 'Timestamp' in df.columns and not df['Timestamp'].empty:\n",
    "        # Check if the first value in the 'Timestamp' column is valid\n",
    "        try:\n",
    "            first_timestamp = pd.to_datetime(df['Timestamp'].iloc[0])  # Get the first timestamp and convert to datetime\n",
    "            dfs.append((df, first_timestamp))\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing timestamp in {file}: {e}\")\n",
    "    else:\n",
    "        print(f\"Skipping file {file} due to missing or empty 'Timestamp' column\")\n",
    "\n",
    "dfs.sort(key=lambda x: x[1])\n",
    "sorted_dfs = [df for df, _ in dfs]\n",
    "\n",
    "final_df = pd.concat(sorted_dfs, axis=0 ,ignore_index=True)\n",
    "final_df.to_csv(\"./icc/icc_tests_bbb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25545/2400456527.py:3: DtypeWarning: Columns (19,21,22,25,26,28,29,30,34,37,38,39,40,41,44,45,46,47,50,51,52,53,54,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  icc_tests_bbb_df = pd.read_csv(\"./icc/icc_tests_bbb.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "icc_tests_bbb_df = pd.read_csv(\"./icc/icc_tests_bbb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'MatchID', 'Innings', 'Over', 'Id', 'Timestamp', 'Runs',\n",
       "       'ZAD', 'Detail', 'Isball', 'Bowler', 'Bowler_Name', 'Batsman',\n",
       "       'Batsman_Name', 'Commentary', 'Iswicket', 'Dismissed', 'Isboundary',\n",
       "       'Summary', 'Batsman_Style', 'Non_Striker', 'Non_Striker_Name', 'Score',\n",
       "       'Batsman_Runs', 'Bowler_Conceded_Runs', 'Dismissal_Type',\n",
       "       'Dismissal_Id', 'Extras_Runs', 'Ball_Speed', 'Howout', 'Fielders',\n",
       "       'Ball_Number', 'Day', 'Session', 'Milestone', 'Over_No', 'Ball',\n",
       "       'Ball_Line_Length', 'This_Over', 'Batsman_Details',\n",
       "       'Non_Striker_Details', 'Bowler_Details', 'Is_Nonball_Wicket',\n",
       "       'Edited_Commentary', 'End_Over', 'Default_Commentary', 'Review_Detail',\n",
       "       'Run_Out_Miss', 'UID', 'OID', 'Bowler_Short_Name', 'Batsman_Short_Name',\n",
       "       'Non_Striker_Short_Name', 'Ball_Speed_This_Over', 'Created_Timestamp',\n",
       "       'IsFreehit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc_tests_bbb_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reshape_comms_info(details):\n",
    "    \"\"\"\n",
    "    Reshape the Batsman, Non-Striker, or Bowler details.\n",
    "    Handles NaN and string parsing for dictionary-like structures.\n",
    "    \"\"\"\n",
    "    # If details is NaN or None, return an empty dictionary\n",
    "    if pd.isna(details) or details is None:\n",
    "        return {}\n",
    "\n",
    "    # If details is a string (e.g., a JSON-like string), try to parse it\n",
    "    if isinstance(details, str):\n",
    "        try:\n",
    "            # Safe evaluation of the string to a dictionary\n",
    "            details = eval(details)\n",
    "        except:\n",
    "            # Return an empty dictionary if parsing fails\n",
    "            return {}\n",
    "\n",
    "    # If the details are a dictionary, process it\n",
    "    if isinstance(details, dict):\n",
    "        reshaped_data = {}\n",
    "        for key, value in details.items():\n",
    "            reshaped_data[key] = value\n",
    "        return reshaped_data\n",
    "\n",
    "    # If the details are neither NaN nor a string or dictionary, return an empty dictionary\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_bat_det_info = icc_tests_bbb_df['Batsman_Details'].apply(reshape_comms_info)\n",
    "reshaped_non_stkr_det_info = icc_tests_bbb_df['Non_Striker_Details'].apply(reshape_comms_info)\n",
    "reshaped_bow_det_info = icc_tests_bbb_df['Bowler_Details'].apply(reshape_comms_info)\n",
    "\n",
    "# Convert the reshaped lists into DataFrames\n",
    "reshaped_bat_det_info_df = pd.DataFrame(reshaped_bat_det_info.tolist())\n",
    "reshaped_non_stkr_det_info_df = pd.DataFrame(reshaped_non_stkr_det_info.tolist())\n",
    "reshaped_bow_det_info_df = pd.DataFrame(reshaped_bow_det_info.tolist())\n",
    "\n",
    "# Add suffixes based on the role for each of the DataFrames\n",
    "reshaped_bat_det_info_df.columns = [f\"curr_striker_{col}\" for col in reshaped_bat_det_info_df.columns]\n",
    "reshaped_non_stkr_det_info_df.columns = [f\"curr_non_striker_{col}\" for col in reshaped_non_stkr_det_info_df.columns]\n",
    "reshaped_bow_det_info_df.columns = [f\"curr_bowler_{col}\" for col in reshaped_bow_det_info_df.columns]\n",
    "\n",
    "# Concatenate the reshaped DataFrames back into the original DataFrame\n",
    "icc_tests_bbb_df = pd.concat([icc_tests_bbb_df, reshaped_non_stkr_det_info_df, reshaped_bow_det_info_df, reshaped_bat_det_info_df], axis=1)\n",
    "\n",
    "# Drop the original details columns\n",
    "icc_tests_bbb_df = icc_tests_bbb_df.drop(columns=['Non_Striker_Details', 'Bowler_Details', 'Batsman_Details'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'MatchID', 'Innings', 'Over', 'Id', 'Timestamp', 'Runs',\n",
       "       'ZAD', 'Detail', 'Isball', 'Bowler', 'Bowler_Name', 'Batsman',\n",
       "       'Batsman_Name', 'Commentary', 'Iswicket', 'Dismissed', 'Isboundary',\n",
       "       'Summary', 'Batsman_Style', 'Non_Striker', 'Non_Striker_Name', 'Score',\n",
       "       'Batsman_Runs', 'Bowler_Conceded_Runs', 'Dismissal_Type',\n",
       "       'Dismissal_Id', 'Extras_Runs', 'Ball_Speed', 'Howout', 'Fielders',\n",
       "       'Ball_Number', 'Day', 'Session', 'Milestone', 'Over_No', 'Ball',\n",
       "       'Ball_Line_Length', 'This_Over', 'Is_Nonball_Wicket',\n",
       "       'Edited_Commentary', 'End_Over', 'Default_Commentary', 'Review_Detail',\n",
       "       'Run_Out_Miss', 'UID', 'OID', 'Bowler_Short_Name', 'Batsman_Short_Name',\n",
       "       'Non_Striker_Short_Name', 'Ball_Speed_This_Over', 'Created_Timestamp',\n",
       "       'IsFreehit', 'curr_non_striker_Runs', 'curr_non_striker_Balls',\n",
       "       'curr_non_striker_Fours', 'curr_non_striker_Sixes',\n",
       "       'curr_non_striker_Batsman', 'curr_bowler_Overs', 'curr_bowler_Maidens',\n",
       "       'curr_bowler_Runs', 'curr_bowler_Wickets', 'curr_bowler_Bowler',\n",
       "       'curr_striker_Runs', 'curr_striker_Balls', 'curr_striker_Fours',\n",
       "       'curr_striker_Sixes', 'curr_striker_Batsman'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc_tests_bbb_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_tests_bbb_df.drop(columns=['UID', 'OID', 'Bowler_Short_Name', 'Batsman_Short_Name', 'Non_Striker_Short_Name', 'This_Over', 'Ball_Speed_This_Over', 'Default_Commentary', 'Commentary', 'Id', 'Edited_Commentary', 'Isball'], inplace=True)\n",
    "icc_tests_bbb_df.to_csv(\"./icc/icc_tests_bbb_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'MatchID', 'Innings', 'Over', 'Timestamp', 'Runs', 'ZAD',\n",
       "       'Detail', 'Bowler', 'Bowler_Name', 'Batsman', 'Batsman_Name',\n",
       "       'Iswicket', 'Dismissed', 'Isboundary', 'Summary', 'Batsman_Style',\n",
       "       'Non_Striker', 'Non_Striker_Name', 'Score', 'Batsman_Runs',\n",
       "       'Bowler_Conceded_Runs', 'Dismissal_Type', 'Dismissal_Id', 'Extras_Runs',\n",
       "       'Ball_Speed', 'Howout', 'Fielders', 'Ball_Number', 'Day', 'Session',\n",
       "       'Milestone', 'Over_No', 'Ball', 'Ball_Line_Length', 'Is_Nonball_Wicket',\n",
       "       'End_Over', 'Review_Detail', 'Run_Out_Miss', 'Created_Timestamp',\n",
       "       'IsFreehit', 'curr_non_striker_Runs', 'curr_non_striker_Balls',\n",
       "       'curr_non_striker_Fours', 'curr_non_striker_Sixes',\n",
       "       'curr_non_striker_Batsman', 'curr_bowler_Overs', 'curr_bowler_Maidens',\n",
       "       'curr_bowler_Runs', 'curr_bowler_Wickets', 'curr_bowler_Bowler',\n",
       "       'curr_striker_Runs', 'curr_striker_Balls', 'curr_striker_Fours',\n",
       "       'curr_striker_Sixes', 'curr_striker_Batsman'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc_tests_bbb_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25545/2846077226.py:2: DtypeWarning: Columns (16,18,19,22,23,25,26,27,31,34,36,37,38,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./icc/icc_tests_bbb_final.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'MatchID', 'Innings', 'Over', 'Timestamp', 'Runs', 'ZAD',\n",
       "       'Detail', 'Bowler', 'Bowler_Name', 'Batsman', 'Batsman_Name',\n",
       "       'Iswicket', 'Dismissed', 'Isboundary', 'Summary', 'Batsman_Style',\n",
       "       'Non_Striker', 'Non_Striker_Name', 'Score', 'Batsman_Runs',\n",
       "       'Bowler_Conceded_Runs', 'Dismissal_Type', 'Dismissal_Id', 'Extras_Runs',\n",
       "       'Ball_Speed', 'Howout', 'Fielders', 'Ball_Number', 'Day', 'Session',\n",
       "       'Milestone', 'Over_No', 'Ball', 'Ball_Line_Length', 'Is_Nonball_Wicket',\n",
       "       'End_Over', 'Review_Detail', 'Run_Out_Miss', 'Created_Timestamp',\n",
       "       'IsFreehit', 'curr_non_striker_Runs', 'curr_non_striker_Balls',\n",
       "       'curr_non_striker_Fours', 'curr_non_striker_Sixes',\n",
       "       'curr_non_striker_Batsman', 'curr_bowler_Overs', 'curr_bowler_Maidens',\n",
       "       'curr_bowler_Runs', 'curr_bowler_Wickets', 'curr_bowler_Bowler',\n",
       "       'curr_striker_Runs', 'curr_striker_Balls', 'curr_striker_Fours',\n",
       "       'curr_striker_Sixes', 'curr_striker_Batsman'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./icc/icc_tests_bbb_final.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Unnamed: 0', 'MatchID', 'Innings', 'Over', 'Timestamp', \n",
    "       'Bowler', 'Bowler_Name', 'Batsman',\n",
    "       'Batsman_Name', 'Batsman_Style', 'Non_Striker', 'Non_Striker_Name',\n",
    "\n",
    "       'curr_bowler_Overs', 'curr_bowler_Maidens', 'curr_bowler_Runs', 'curr_bowler_Wickets', 'curr_bowler_Bowler', \n",
    "       'curr_striker_Runs', 'curr_striker_Balls', 'curr_striker_Fours', 'curr_striker_Sixes', 'curr_striker_Batsman', \n",
    "       'curr_non_striker_Runs', 'curr_non_striker_Balls', 'curr_non_striker_Fours', 'curr_non_striker_Sixes', 'curr_non_striker_Batsman',\n",
    "\n",
    "       'Score', 'ZAD', 'Ball_Speed','Ball_Number', 'Day', 'Session', 'End_Over', 'Over_No', 'Ball', 'Ball_Line_Length',\n",
    "\n",
    "       'Runs', 'Batsman_Runs', 'Bowler_Conceded_Runs', 'Extras_Runs', 'Detail', 'Isboundary',\n",
    "       'Iswicket', 'Dismissed', 'Dismissal_Type','Dismissal_Id', 'Howout', 'Fielders',\n",
    "\n",
    "       'Is_Nonball_Wicket', 'Milestone', 'Review_Detail', 'Run_Out_Miss', 'IsFreehit',\n",
    "       'Summary']\n",
    "\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.to_csv(\"./icc/icc_tests_bbb_final.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
