{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup_from_url(url):\n",
    "    # Helper to get response soup from url\n",
    "    sleep(1)\n",
    "    try:\n",
    "        html = urlopen(url).read()\n",
    "    except HTTPError:\n",
    "        print(\"Link Cannot be Reached\")\n",
    "        return -1\n",
    "    #soup = BeautifulSoup(html,\"lxml\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_matchids_for_season(season='2018/19'):\n",
    "    #season = \"2018\"\n",
    "    #season = \"2018/19\"\n",
    "    season = season.replace('/', '%2F')\n",
    "    url = \"http://www.espncricinfo.com/ci/engine/series/index.html?season={};view=season\".format(season)\n",
    "    soup = get_soup_from_url(url)\n",
    "    d={}\n",
    "    for section in soup.find_all('div', class_='match-section-head'):\n",
    "        series_in_section = [series['data-series-id']\n",
    "                             for series in section.find_next(\n",
    "                                 'section',\n",
    "                                  class_='series-summary-wrap'\n",
    "                             ).find_all(\n",
    "                                 'section',\n",
    "                                  class_=\"series-summary-block collapsed\"\n",
    "                             )\n",
    "                            ]\n",
    "        series_in_section = [\n",
    "            get_soup_from_url('http://www.espncricinfo.com/ci/engine/match/index/series.html?series={}'.format(s)) \n",
    "            for s in series_in_section\n",
    "        ]\n",
    "        matches_in_section = [\n",
    "            re.findall('\\/([0-9]+)\\/', \n",
    "                      m.find('a')['href'])[1] \n",
    "            for ss in series_in_section \n",
    "            for m in ss.find_all(class_='match-no')\n",
    "        ]\n",
    "        d[section.text] = matches_in_section\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ids_2024 = get_all_matchids_for_season('2024')\n",
    "match_ids = match_ids_2024['Tests']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If You Have matchid.txt From CRICSHEET Which Is A List Of Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# with open('matchid.txt', 'r') as file:\n",
    "#     text = file.read()\n",
    "\n",
    "# match_ids = re.findall(r'\\b\\d{7}\\b', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_redirected_commentary_url(match_id, return_type=2):\n",
    "    # Construct the original match URL\n",
    "    original_url = f\"https://www.espncricinfo.com/matches/engine/match/{match_id}.html\"\n",
    "    \n",
    "    # Perform a HEAD request to get the redirected URL\n",
    "    response = requests.head(original_url, allow_redirects=True)\n",
    "    redirected_url = response.url\n",
    "\n",
    "    # Modify the redirected URL for commentary\n",
    "    if \"full-scorecard\" in redirected_url:\n",
    "        commentary_url = redirected_url.replace(\"full-scorecard\", \"ball-by-ball-commentary\")\n",
    "    elif \"live-cricket-score\" in redirected_url:\n",
    "        commentary_url = redirected_url.replace(\"live-cricket-score\", \"ball-by-ball-commentary\")\n",
    "    else:\n",
    "        raise ValueError(\"Redirected URL does not contain expected parts ('full-scorecard' or 'live-cricket-score'). Cannot modify to commentary URL.\")\n",
    "\n",
    "    # Return the appropriate URL based on return_type\n",
    "    if return_type == 1:\n",
    "        return redirected_url\n",
    "    elif return_type == 2:\n",
    "        return commentary_url\n",
    "    else:\n",
    "        raise ValueError(\"Invalid return_type. Use 1 for redirected URL or 2 for commentary URL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Setup Chrome options\n",
    "\n",
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "    options.add_argument(\"--disable-plugins\")\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.set_capability('goog:loggingPrefs', {'performance': 'ALL'})\n",
    "\n",
    "    options.page_load_strategy = 'eager'\n",
    "    options.set_capability('goog:loggingPrefs', {'performance': 'ALL'})\n",
    "\n",
    "    # Limit network resources\n",
    "    options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "\n",
    "    # Initialize WebDriver\n",
    "    service = Service('/usr/bin/chromedriver')\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    return driver\n",
    "\n",
    "# Dictionary to store different types of API URLs\n",
    "\n",
    "# \n",
    "\n",
    "def capture_and_categorize_urls(driver, api_responses, api_url_types, type):\n",
    "    logs = driver.get_log('performance')\n",
    "    for entry in logs:\n",
    "        try:\n",
    "            log = json.loads(entry['message'])['message']\n",
    "            if log.get('method') == 'Network.responseReceived':\n",
    "                response_url = log.get('params', {}).get('response', {}).get('url', '')\n",
    "                \n",
    "                check_str = ''\n",
    "                if(type == 1):\n",
    "                    check_str = 'hs-consumer-api.espncricinfo.com/v1/pages/match/scorecard'\n",
    "                else:\n",
    "                    check_str = 'hs-consumer-api.espncricinfo.com/v1/pages/match/comments'\n",
    "\n",
    "                # Check if the URL contains the desired comment API URL\n",
    "                if check_str in response_url:\n",
    "                    # Check if the sortDirection is ASC\n",
    "                    if type == 1 :\n",
    "                        print(f\"Captured Fetch Request URL: {response_url}\")\n",
    "                        \n",
    "                        # Extract the response body using CDP\n",
    "                        request_id = log['params']['requestId']\n",
    "                        \n",
    "                        response_body = driver.execute_cdp_cmd(\n",
    "                            'Network.getResponseBody',\n",
    "                            {'requestId': request_id}\n",
    "                        )\n",
    "\n",
    "                        # Add to responses list\n",
    "                        api_responses.append({\n",
    "                            \"url\": response_url,\n",
    "                            \"body\": json.loads(response_body.get('body', '{}'))  # Parse JSON body\n",
    "                        })\n",
    "                        \n",
    "                        # Categorize based on the unique identifier in the URL\n",
    "                        match = re.search(r'/comments/(\\w+)', response_url)\n",
    "                        if match:\n",
    "                            if match.group(1) == 'default':\n",
    "                                api_url_types['comments_urls'].add(response_url)\n",
    "                            else:\n",
    "                                api_url_types['other_comments_urls'].add(response_url)\n",
    "\n",
    "                        print(f\"Captured Scorecard URL: {response_url}\")   \n",
    "\n",
    "                    elif 'sortDirection=ASC' in response_url:\n",
    "                        # Process only the URLs where sortDirection=ASC\n",
    "                        print(f\"Captured Fetch Request URL (ASC): {response_url}\")\n",
    "                        \n",
    "                        # Extract the response body using CDP\n",
    "                        request_id = log['params']['requestId']\n",
    "                        response_body = driver.execute_cdp_cmd(\n",
    "                            'Network.getResponseBody',\n",
    "                            {'requestId': request_id}\n",
    "                        )\n",
    "\n",
    "                        # Add to responses list\n",
    "                        api_responses.append({\n",
    "                            \"url\": response_url,\n",
    "                            \"body\": json.loads(response_body.get('body', '{}'))  # Parse JSON body\n",
    "                        })\n",
    "                        \n",
    "                        # Categorize based on the unique identifier in the URL\n",
    "                        match = re.search(r'/comments/(\\w+)', response_url)\n",
    "                        if match:\n",
    "                            if match.group(1) == 'default':\n",
    "                                api_url_types['comments_urls'].add(response_url)\n",
    "                            else:\n",
    "                                api_url_types['other_comments_urls'].add(response_url)\n",
    "\n",
    "                        print(f\"Captured Comments URL (ASC): {response_url}\")\n",
    "                    else:\n",
    "                        print(f\"Skipping URL with sortDirection=DESC: {response_url}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error capturing URL: {e}\")\n",
    "            continue\n",
    "\n",
    "def scroll_page_func(driver, api_responses, api_url_types):\n",
    "    scroll_increment = 200\n",
    "    scroll_pause_time = 1\n",
    "    page_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    current_position = 0\n",
    "\n",
    "    while current_position < page_height:\n",
    "        # Scroll down\n",
    "        driver.execute_script(f\"window.scrollBy(0, {scroll_increment});\")\n",
    "        current_position += scroll_increment\n",
    "        time.sleep(scroll_pause_time)\n",
    "\n",
    "        # Update page height\n",
    "        page_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        # Capture URLs\n",
    "        capture_and_categorize_urls(driver, api_responses, api_url_types, 2)\n",
    "\n",
    "    print(\"Scrolling and URL capture completed.\")\n",
    "\n",
    "def espn_commentary_scrapper_engine(url, match_id):\n",
    "\n",
    "    api_url_types = {\n",
    "        'comments_urls': set(),\n",
    "        'other_comments_urls': set()\n",
    "    }\n",
    "\n",
    "    api_responses = []\n",
    "    \n",
    "\n",
    "    driver = setup_driver()\n",
    "\n",
    "    try:\n",
    "        # Open the target webpage\n",
    "        driver.get(url)\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        # innings_dropdown = driver.find_element(By.XPATH, \"//div[contains(@class, 'ds-popper-wrapper') and .//span[contains(@class, 'ds-text-tight-s')]]\")\n",
    "        innings_dropdown = driver.find_element(By.XPATH, \"//div[@class='ds-popper-wrapper']//div[contains(@class, 'ds-flex ds-items-center ds-border-ui-stroke ds-h-6 ds-px-4 ds-border ds-bg-ui-fill ds-rounded-full ds-w-full ds-min-w-max ds-cursor-pointer')]\")\n",
    "        driver.execute_script(\"arguments[0].click();\", innings_dropdown)\n",
    "        # driver.execute_script(\"arguments[0].setAttribute('aria-expanded', 'true');\", innings_dropdown)\n",
    "        \n",
    "        # time.sleep(2)\n",
    "          # This will help you debug the issue\n",
    "\n",
    "        li_elements = WebDriverWait(driver, 3).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, \"//ul[contains(@class, 'ds-flex ds-flex-col')]//li\"))\n",
    "            # EC.visibility_of_all_elements_located((By.XPATH, \"//ul[contains(@class, 'ds-flex ds-flex-col')]//li\"))\n",
    "        )\n",
    "\n",
    "        no_of_innings = len(li_elements)\n",
    "\n",
    "        for i in range(no_of_innings):\n",
    "            \n",
    "            driver.get(url)\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            # innings_dropdown = driver.find_element(By.XPATH, \"//div[contains(@class, 'ds-popper-wrapper') and .//span[contains(@class, 'ds-text-tight-s')]]\")\n",
    "            # driver.execute_script(\"arguments[0].click();\", innings_dropdown)\n",
    "\n",
    "            innings_dropdown = driver.find_element(By.XPATH, \"//div[@class='ds-popper-wrapper']//div[contains(@class, 'ds-flex ds-items-center ds-border-ui-stroke ds-h-6 ds-px-4 ds-border ds-bg-ui-fill ds-rounded-full ds-w-full ds-min-w-max ds-cursor-pointer')]\")\n",
    "            driver.execute_script(\"arguments[0].click();\", innings_dropdown)\n",
    "            # innings_dropdown.click()\n",
    "            # time.sleep(2)\n",
    "            # print(driver.page_source)\n",
    "            li_elements = WebDriverWait(driver, 3).until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, \"//ul[contains(@class, 'ds-flex ds-flex-col')]//li\"))\n",
    "            )\n",
    "\n",
    "            span_element = li_elements[i].find_element(By.XPATH, \".//span\")\n",
    "            driver.execute_script(\"arguments[0].click();\", span_element)\n",
    "            # continue\n",
    "            buttons = driver.find_element(By.XPATH, \"//span[contains(@class, 'ds-inline-flex') and .//span[text()='New']]\")\n",
    "            driver.execute_script(\"arguments[0].click();\", buttons)\n",
    "            driver.get_log('performance')\n",
    "            # li_elements[2].click()\n",
    "            # driver.execute_script(\"arguments[0].click();\", li_elements[i])\n",
    "\n",
    "            \n",
    "            inn_name = str(match_id) + \".json\"\n",
    "            # print(inn_name)\n",
    "            time.sleep(2)\n",
    "\n",
    "            # driver.get_log('performance')\n",
    "            scroll_page_func(driver, api_responses, api_url_types)\n",
    "\n",
    "            folder_path = \"espn_scrape_data/matches\"\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "            file_path = os.path.join(folder_path, inn_name)\n",
    "\n",
    "            with open(file_path, 'w') as f:\n",
    "                json.dump(api_responses, f, indent=4)\n",
    "                # json.dump({k: list(v) for k, v in api_url_types.items()}, f, indent=4)\n",
    "                print(f\"API URLs saved to {folder_path}/{inn_name}.\", folder_path,inn_name)\n",
    "            \n",
    "            # api_responses = []\n",
    "            \n",
    "        # Setup scroll parameters\n",
    "        \n",
    "\n",
    "        # Save the categorized URLs to a file\n",
    "\n",
    "        # Print out the differences\n",
    "        print(\"\\nDifferences in Comments API URLs:\")\n",
    "        print(\"Default Comments URLs:\", len(api_url_types['comments_urls']))\n",
    "        print(\"Other Comments URLs:\", len(api_url_types['other_comments_urls']))\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "def espn_scorecard_scrapper_engine(url, match_id):\n",
    "\n",
    "    api_url_types = {\n",
    "        'comments_urls': set(),\n",
    "        'other_comments_urls': set()\n",
    "    }\n",
    "\n",
    "    api_responses = []\n",
    "    \n",
    "\n",
    "    driver = setup_driver()\n",
    "\n",
    "    try:\n",
    "        # Open the target webpage\n",
    "        driver.get(url)\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        inn_name = str(match_id) + \"_scorecard.json\"    \n",
    "        # Wait until the element is present (modify the time as needed)\n",
    "        wait = WebDriverWait(driver, 3)\n",
    "        element = wait.until(\n",
    "\n",
    "            EC.presence_of_all_elements_located(\n",
    "                (By.XPATH, \"//a[contains(@href, '/full-scorecard')]\")\n",
    "            )\n",
    "\n",
    "        )\n",
    "\n",
    "        # Click the element\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", element[1])\n",
    "        driver.execute_script(\"arguments[0].click();\", element[1])\n",
    "\n",
    "        time.sleep(2)\n",
    "        capture_and_categorize_urls(driver, api_responses, api_url_types, 1)\n",
    "\n",
    "        folder_path = \"espn_scrape_data/scorecard\"\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        file_path = os.path.join(folder_path, inn_name)\n",
    "\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(api_responses, f, indent=4)\n",
    "            # json.dump({k: list(v) for k, v in api_url_types.items()}, f, indent=4)\n",
    "            print(f\"API URLs saved to {folder_path}/{inn_name}.\", folder_path,inn_name)\n",
    "        \n",
    "        # api_responses = []\n",
    "            \n",
    "        print(\"\\nDifferences in Comments API URLs:\")\n",
    "        print(\"Default Comments URLs:\", len(api_url_types['comments_urls']))\n",
    "        print(\"Other Comments URLs:\", len(api_url_types['other_comments_urls']))\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        \n",
    "# if __name__ == \"__main__\":\n",
    "#     espn_commentary_scrapper_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# espn_commentary_scrapper_engine(get_redirected_commentary_url(1432209, 2), 1432209)\n",
    "# espn_scorecard_scrapper_engine(get_redirected_commentary_url(1428556, 1), 1428556)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured Fetch Request URL (ASC): https://hs-consumer-api.espncricinfo.com/v1/pages/match/comments?lang=en&seriesId=1442205&matchId=1442215&inningNumber=2&commentType=ALL&sortDirection=ASC&fromInningOver=38\n",
      "Error capturing URL: Message: unknown error: unhandled inspector error: {\"code\":-32000,\"message\":\"No resource with given identifier found\"}\n",
      "  (Session info: chrome=131.0.6778.139)\n",
      "Stacktrace:\n",
      "#0 0x566d60939efa <unknown>\n",
      "#1 0x566d604626c0 <unknown>\n",
      "#2 0x566d60449f63 <unknown>\n",
      "#3 0x566d6044882c <unknown>\n",
      "#4 0x566d604490cf <unknown>\n",
      "#5 0x566d60449024 <unknown>\n",
      "#6 0x566d60465c4f <unknown>\n",
      "#7 0x566d604fee1a <unknown>\n",
      "#8 0x566d604d4572 <unknown>\n",
      "#9 0x566d604f2c4e <unknown>\n",
      "#10 0x566d604d4313 <unknown>\n",
      "#11 0x566d604a2fcf <unknown>\n",
      "#12 0x566d604a3fee <unknown>\n",
      "#13 0x566d609082df <unknown>\n",
      "#14 0x566d6090c3fd <unknown>\n",
      "#15 0x566d608f6977 <unknown>\n",
      "#16 0x566d6090cb71 <unknown>\n",
      "#17 0x566d608de96e <unknown>\n",
      "#18 0x566d60928c18 <unknown>\n",
      "#19 0x566d60928e1a <unknown>\n",
      "#20 0x566d60938b6c <unknown>\n",
      "#21 0x788032783ac3 <unknown>\n",
      "\n",
      "Captured Fetch Request URL (ASC): https://hs-consumer-api.espncricinfo.com/v1/pages/match/comments?lang=en&seriesId=1442205&matchId=1442215&inningNumber=2&commentType=ALL&sortDirection=ASC&fromInningOver=38\n",
      "Captured Comments URL (ASC): https://hs-consumer-api.espncricinfo.com/v1/pages/match/comments?lang=en&seriesId=1442205&matchId=1442215&inningNumber=2&commentType=ALL&sortDirection=ASC&fromInningOver=38\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Wrapper function to integrate both steps\n",
    "def process_match(match_id):\n",
    "    # Step 1: Get the redirected commentary URL\n",
    "    commentary_url = get_redirected_commentary_url(match_id, 2)\n",
    "    # Step 2: Pass the URL and match ID to the scraper engine\n",
    "    espn_commentary_scrapper_engine(commentary_url, match_id)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# Run the scraping process in parallel\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:  # Adjust max_workers as needed\n",
    "    executor.map(process_match, match_ids)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in match_ids:\n",
    "#     espn_scorecard_scrapper_engine(get_redirected_commentary_url(i, 1), i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
